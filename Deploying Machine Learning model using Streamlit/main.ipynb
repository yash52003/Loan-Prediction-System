{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QAeiOPwanDJT","executionInfo":{"status":"ok","timestamp":1681643241090,"user_tz":-330,"elapsed":811,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["import pandas as pd\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"n4kHit4unDJX","executionInfo":{"status":"ok","timestamp":1681643241091,"user_tz":-330,"elapsed":6,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["data = pd.read_csv(\"/content/drive/MyDrive/Model Deployment/LoanApp V_2/Deploying Machine Learning model using Streamlit/loan_data.csv\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIzypdp4nRg4","executionInfo":{"status":"ok","timestamp":1681643251991,"user_tz":-330,"elapsed":10905,"user":{"displayName":"Study Material","userId":"09920973746406953302"}},"outputId":"daca359d-282f-47f1-9654-a80bdee05952"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mqXJkCMGnDJY","executionInfo":{"status":"ok","timestamp":1681643251992,"user_tz":-330,"elapsed":48,"user":{"displayName":"Study Material","userId":"09920973746406953302"}},"outputId":"7a01e26d-2669-4db3-b0e1-b7eef5119641"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Gender Married  ApplicantIncome  LoanAmount Loan_Status\n","0   Male     Yes             4583    128000.0           N\n","1   Male     Yes             3000     66000.0           Y\n","2   Male     Yes             2583    120000.0           Y\n","3   Male      No             6000    141000.0           Y\n","4   Male     Yes             5417    267000.0           Y"],"text/html":["\n","  <div id=\"df-fa0777f0-5e7c-4b64-a726-61701cb1fa71\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Married</th>\n","      <th>ApplicantIncome</th>\n","      <th>LoanAmount</th>\n","      <th>Loan_Status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>4583</td>\n","      <td>128000.0</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>3000</td>\n","      <td>66000.0</td>\n","      <td>Y</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>2583</td>\n","      <td>120000.0</td>\n","      <td>Y</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>6000</td>\n","      <td>141000.0</td>\n","      <td>Y</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>5417</td>\n","      <td>267000.0</td>\n","      <td>Y</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa0777f0-5e7c-4b64-a726-61701cb1fa71')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fa0777f0-5e7c-4b64-a726-61701cb1fa71 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fa0777f0-5e7c-4b64-a726-61701cb1fa71');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yBE4reNMnDJZ","executionInfo":{"status":"ok","timestamp":1681643251993,"user_tz":-330,"elapsed":46,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["data.Gender = data.Gender.map({\"Male\" : 1 , \"Female\" : 0})"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"aAYtY9UmnDJZ","executionInfo":{"status":"ok","timestamp":1681643251994,"user_tz":-330,"elapsed":46,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["data.Married = data.Married.map({\"Yes\" : 1 , \"No\" : 0})"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"USM6zigdnDJa","executionInfo":{"status":"ok","timestamp":1681643251995,"user_tz":-330,"elapsed":47,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["data.Loan_Status = data.Loan_Status.map({\"Y\" : 1 , \"N\":0})"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"vZzgzRvKnDJb","executionInfo":{"status":"ok","timestamp":1681643251995,"user_tz":-330,"elapsed":46,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["aIncome_max = data.ApplicantIncome.max()\n","aIncome_min = data.ApplicantIncome.min()\n","loanAmount_max = data.LoanAmount.max()\n","loanAmount_min = data.LoanAmount.min()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1U8Lq7TVnDJb","executionInfo":{"status":"ok","timestamp":1681643251996,"user_tz":-330,"elapsed":47,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["# data.ApplicantIncome = (data.ApplicantIncome - aIncome_min)/(aIncome_max)\n","# data.LoanAmount = (data.LoanAmount - loanAmount_min)/(loanAmount_max)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"aL0hTd2CnDJc","executionInfo":{"status":"ok","timestamp":1681643251999,"user_tz":-330,"elapsed":49,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["X = data.drop(\"Loan_Status\", axis=1)\n","y = data[\"Loan_Status\"]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"1USqOMwQnDJe","executionInfo":{"status":"ok","timestamp":1681643253916,"user_tz":-330,"elapsed":1966,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, InputLayer\n","from keras.initializers import random_normal"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"LZCNnz4gnDJf","executionInfo":{"status":"ok","timestamp":1681643253917,"user_tz":-330,"elapsed":8,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split as tts\n","train_x,val_x, train_y, val_y = tts(X,y,test_size= 0.10,stratify=y)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fqmC2u0nDJg","executionInfo":{"status":"ok","timestamp":1681643253917,"user_tz":-330,"elapsed":7,"user":{"displayName":"Study Material","userId":"09920973746406953302"}},"outputId":"caf8f3c1-2962-49a1-b3e5-ef4bddc9e457"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((519, 4), (58, 4))"]},"metadata":{},"execution_count":13}],"source":["train_x.shape, val_x.shape"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"TTFgd4EXnDJg","executionInfo":{"status":"ok","timestamp":1681643255790,"user_tz":-330,"elapsed":1878,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["model = Sequential()\n","model.add(InputLayer(input_shape=(train_x.shape[1])))\n","model.add(Dense(units=30, activation=\"relu\", kernel_initializer=\"random_normal\"))\n","model.add(Dense(units = 10 , activation=\"relu\", kernel_initializer=\"random_normal\"))\n","model.add(Dense(units=1 , activation=\"sigmoid\"))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ZI0vvWU4nDJg","executionInfo":{"status":"ok","timestamp":1681643255791,"user_tz":-330,"elapsed":21,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["model.compile(loss = \"binary_crossentropy\" , optimizer=\"Adam\" , metrics=\"accuracy\")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"x4kBwS2snDJh","executionInfo":{"status":"ok","timestamp":1681643255792,"user_tz":-330,"elapsed":21,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint\n","filepath = 'checkpoint.hdf5'\n","model_checkpoint_callback = ModelCheckpoint(filepath,monitor=\"val_accuracy\" , verbose=1,save_best_only=True,)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bM5IUczxnDJh","executionInfo":{"status":"ok","timestamp":1681643267755,"user_tz":-330,"elapsed":11983,"user":{"displayName":"Study Material","userId":"09920973746406953302"}},"outputId":"d8e4169b-3ee3-43af-fe89-dea9f7588a40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/6 [====>.........................] - ETA: 12s - loss: 1.9799 - accuracy: 0.7200\n","Epoch 1: val_accuracy improved from -inf to 0.68966, saving model to checkpoint.hdf5\n","6/6 [==============================] - 3s 46ms/step - loss: 38.0324 - accuracy: 0.5588 - val_loss: 32.2154 - val_accuracy: 0.6897\n","Epoch 2/100\n","1/6 [====>.........................] - ETA: 0s - loss: 25.9577 - accuracy: 0.7100\n","Epoch 2: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 19.2473 - accuracy: 0.5299 - val_loss: 12.2990 - val_accuracy: 0.6897\n","Epoch 3/100\n","1/6 [====>.........................] - ETA: 0s - loss: 8.7163 - accuracy: 0.7200\n","Epoch 3: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 8ms/step - loss: 19.8722 - accuracy: 0.6956 - val_loss: 5.9015 - val_accuracy: 0.3103\n","Epoch 4/100\n","1/6 [====>.........................] - ETA: 0s - loss: 5.0132 - accuracy: 0.3900\n","Epoch 4: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 9.2551 - accuracy: 0.4875 - val_loss: 10.1196 - val_accuracy: 0.6897\n","Epoch 5/100\n","1/6 [====>.........................] - ETA: 0s - loss: 7.2182 - accuracy: 0.7300\n","Epoch 5: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 10ms/step - loss: 5.1763 - accuracy: 0.5761 - val_loss: 2.9629 - val_accuracy: 0.3621\n","Epoch 6/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.3921 - accuracy: 0.3600\n","Epoch 6: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 3.0718 - accuracy: 0.5703 - val_loss: 2.2626 - val_accuracy: 0.6897\n","Epoch 7/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.9967 - accuracy: 0.6900\n","Epoch 7: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 11ms/step - loss: 2.4484 - accuracy: 0.6069 - val_loss: 4.4471 - val_accuracy: 0.6897\n","Epoch 8/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.4374 - accuracy: 0.7100\n","Epoch 8: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 3.6152 - accuracy: 0.5934 - val_loss: 2.6900 - val_accuracy: 0.6897\n","Epoch 9/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.8304 - accuracy: 0.5700\n","Epoch 9: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 6.0087 - accuracy: 0.5453 - val_loss: 6.1110 - val_accuracy: 0.6897\n","Epoch 10/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.4842 - accuracy: 0.7100\n","Epoch 10: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 8ms/step - loss: 5.5767 - accuracy: 0.5395 - val_loss: 5.0027 - val_accuracy: 0.6897\n","Epoch 11/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.2893 - accuracy: 0.7100\n","Epoch 11: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 11ms/step - loss: 6.7646 - accuracy: 0.4913 - val_loss: 10.9737 - val_accuracy: 0.6897\n","Epoch 12/100\n","1/6 [====>.........................] - ETA: 0s - loss: 11.1228 - accuracy: 0.6600\n","Epoch 12: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 9.7974 - accuracy: 0.5145 - val_loss: 7.0474 - val_accuracy: 0.6897\n","Epoch 13/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.3408 - accuracy: 0.6900\n","Epoch 13: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 10.4331 - accuracy: 0.6956 - val_loss: 15.6294 - val_accuracy: 0.3103\n","Epoch 14/100\n","1/6 [====>.........................] - ETA: 0s - loss: 12.8211 - accuracy: 0.3200\n","Epoch 14: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 8ms/step - loss: 11.3063 - accuracy: 0.4836 - val_loss: 22.4534 - val_accuracy: 0.6897\n","Epoch 15/100\n","1/6 [====>.........................] - ETA: 0s - loss: 19.5465 - accuracy: 0.7600\n","Epoch 15: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 13.7491 - accuracy: 0.6050 - val_loss: 3.5553 - val_accuracy: 0.3103\n","Epoch 16/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.1235 - accuracy: 0.3000\n","Epoch 16: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 8.5108 - accuracy: 0.6185 - val_loss: 1.1824 - val_accuracy: 0.3103\n","Epoch 17/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.1869 - accuracy: 0.3100\n","Epoch 17: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 3.3122 - accuracy: 0.5299 - val_loss: 2.0191 - val_accuracy: 0.6897\n","Epoch 18/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.2254 - accuracy: 0.5900\n","Epoch 18: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 8ms/step - loss: 2.2375 - accuracy: 0.6050 - val_loss: 7.1032 - val_accuracy: 0.3103\n","Epoch 19/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.7159 - accuracy: 0.2600\n","Epoch 19: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 8ms/step - loss: 3.3291 - accuracy: 0.5299 - val_loss: 1.8143 - val_accuracy: 0.6897\n","Epoch 20/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.6718 - accuracy: 0.6300\n","Epoch 20: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 2.4676 - accuracy: 0.5896 - val_loss: 3.7964 - val_accuracy: 0.3103\n","Epoch 21/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.2178 - accuracy: 0.3300\n","Epoch 21: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 5.5862 - accuracy: 0.6224 - val_loss: 2.5064 - val_accuracy: 0.3103\n","Epoch 22/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.3665 - accuracy: 0.2800\n","Epoch 22: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 4.0765 - accuracy: 0.5992 - val_loss: 8.7699 - val_accuracy: 0.3103\n","Epoch 23/100\n","1/6 [====>.........................] - ETA: 0s - loss: 7.3648 - accuracy: 0.3100\n","Epoch 23: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 4.7129 - accuracy: 0.6089 - val_loss: 7.9330 - val_accuracy: 0.3103\n","Epoch 24/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.0562 - accuracy: 0.3700\n","Epoch 24: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 3.2595 - accuracy: 0.5549 - val_loss: 0.9329 - val_accuracy: 0.6724\n","Epoch 25/100\n","1/6 [====>.........................] - ETA: 0s - loss: 0.6151 - accuracy: 0.7400\n","Epoch 25: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 10ms/step - loss: 1.8037 - accuracy: 0.5337 - val_loss: 5.8446 - val_accuracy: 0.6897\n","Epoch 26/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.1556 - accuracy: 0.6500\n","Epoch 26: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 8ms/step - loss: 2.6302 - accuracy: 0.5222 - val_loss: 1.9262 - val_accuracy: 0.3103\n","Epoch 27/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.7982 - accuracy: 0.3400\n","Epoch 27: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 3.0769 - accuracy: 0.5395 - val_loss: 5.9602 - val_accuracy: 0.6897\n","Epoch 28/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.9198 - accuracy: 0.7400\n","Epoch 28: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 5.8059 - accuracy: 0.6050 - val_loss: 6.3232 - val_accuracy: 0.6897\n","Epoch 29/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.1341 - accuracy: 0.7000\n","Epoch 29: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 7.8687 - accuracy: 0.6936 - val_loss: 2.7440 - val_accuracy: 0.3103\n","Epoch 30/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.0150 - accuracy: 0.4400\n","Epoch 30: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 10ms/step - loss: 3.8571 - accuracy: 0.6590 - val_loss: 6.1650 - val_accuracy: 0.3103\n","Epoch 31/100\n","1/6 [====>.........................] - ETA: 0s - loss: 5.6435 - accuracy: 0.2400\n","Epoch 31: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 7.4704 - accuracy: 0.5954 - val_loss: 12.7642 - val_accuracy: 0.3103\n","Epoch 32/100\n","1/6 [====>.........................] - ETA: 0s - loss: 10.6936 - accuracy: 0.3500\n","Epoch 32: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 11.1770 - accuracy: 0.5029 - val_loss: 20.4919 - val_accuracy: 0.6897\n","Epoch 33/100\n","1/6 [====>.........................] - ETA: 0s - loss: 19.8414 - accuracy: 0.6400\n","Epoch 33: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 12.3510 - accuracy: 0.5973 - val_loss: 13.7361 - val_accuracy: 0.3103\n","Epoch 34/100\n","1/6 [====>.........................] - ETA: 0s - loss: 14.0696 - accuracy: 0.2400\n","Epoch 34: val_accuracy did not improve from 0.68966\n","6/6 [==============================] - 0s 9ms/step - loss: 10.9314 - accuracy: 0.5954 - val_loss: 1.9004 - val_accuracy: 0.6724\n","Epoch 35/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.4688 - accuracy: 0.7100\n","Epoch 35: val_accuracy improved from 0.68966 to 0.70690, saving model to checkpoint.hdf5\n","6/6 [==============================] - 0s 12ms/step - loss: 5.2326 - accuracy: 0.5395 - val_loss: 2.2908 - val_accuracy: 0.7069\n","Epoch 36/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.1312 - accuracy: 0.6500\n","Epoch 36: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 9ms/step - loss: 3.6922 - accuracy: 0.5549 - val_loss: 3.4689 - val_accuracy: 0.7069\n","Epoch 37/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.8793 - accuracy: 0.6400\n","Epoch 37: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 9ms/step - loss: 4.9267 - accuracy: 0.5279 - val_loss: 1.6901 - val_accuracy: 0.7069\n","Epoch 38/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.6399 - accuracy: 0.6700\n","Epoch 38: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 9ms/step - loss: 5.2682 - accuracy: 0.5376 - val_loss: 5.2891 - val_accuracy: 0.6897\n","Epoch 39/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.2933 - accuracy: 0.7400\n","Epoch 39: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 9ms/step - loss: 4.5589 - accuracy: 0.5626 - val_loss: 11.5070 - val_accuracy: 0.6897\n","Epoch 40/100\n","1/6 [====>.........................] - ETA: 0s - loss: 11.5597 - accuracy: 0.6600\n","Epoch 40: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 10ms/step - loss: 6.1680 - accuracy: 0.5491 - val_loss: 3.8843 - val_accuracy: 0.6897\n","Epoch 41/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.9085 - accuracy: 0.7000\n","Epoch 41: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 11ms/step - loss: 3.5042 - accuracy: 0.5260 - val_loss: 6.7744 - val_accuracy: 0.6897\n","Epoch 42/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.1778 - accuracy: 0.7000\n","Epoch 42: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 18ms/step - loss: 4.3728 - accuracy: 0.5780 - val_loss: 9.6014 - val_accuracy: 0.6897\n","Epoch 43/100\n","1/6 [====>.........................] - ETA: 0s - loss: 10.1765 - accuracy: 0.6900\n","Epoch 43: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 25ms/step - loss: 6.1432 - accuracy: 0.5434 - val_loss: 5.9541 - val_accuracy: 0.6897\n","Epoch 44/100\n","1/6 [====>.........................] - ETA: 0s - loss: 5.4261 - accuracy: 0.7200\n","Epoch 44: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 5.2260 - accuracy: 0.5838 - val_loss: 3.6302 - val_accuracy: 0.6897\n","Epoch 45/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.3554 - accuracy: 0.5700\n","Epoch 45: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 18ms/step - loss: 3.5032 - accuracy: 0.5549 - val_loss: 13.6992 - val_accuracy: 0.6897\n","Epoch 46/100\n","1/6 [====>.........................] - ETA: 0s - loss: 7.5159 - accuracy: 0.7500\n","Epoch 46: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 24ms/step - loss: 9.3290 - accuracy: 0.6166 - val_loss: 3.1680 - val_accuracy: 0.2931\n","Epoch 47/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.8147 - accuracy: 0.3000\n","Epoch 47: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 18ms/step - loss: 9.6945 - accuracy: 0.6166 - val_loss: 3.7600 - val_accuracy: 0.6897\n","Epoch 48/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.3126 - accuracy: 0.6600\n","Epoch 48: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 22ms/step - loss: 7.3410 - accuracy: 0.4644 - val_loss: 16.0789 - val_accuracy: 0.6897\n","Epoch 49/100\n","1/6 [====>.........................] - ETA: 0s - loss: 13.3689 - accuracy: 0.7100\n","Epoch 49: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 19ms/step - loss: 9.5028 - accuracy: 0.6224 - val_loss: 4.0700 - val_accuracy: 0.3103\n","Epoch 50/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.2281 - accuracy: 0.2000\n","Epoch 50: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 23ms/step - loss: 10.0337 - accuracy: 0.5800 - val_loss: 1.8357 - val_accuracy: 0.6897\n","Epoch 51/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.4286 - accuracy: 0.7500\n","Epoch 51: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 22ms/step - loss: 9.1725 - accuracy: 0.4682 - val_loss: 13.7247 - val_accuracy: 0.6897\n","Epoch 52/100\n","1/6 [====>.........................] - ETA: 0s - loss: 14.9542 - accuracy: 0.7100\n","Epoch 52: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 20ms/step - loss: 9.3697 - accuracy: 0.6050 - val_loss: 3.7928 - val_accuracy: 0.3103\n","Epoch 53/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.1573 - accuracy: 0.3300\n","Epoch 53: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 14.4641 - accuracy: 0.6301 - val_loss: 17.4722 - val_accuracy: 0.6897\n","Epoch 54/100\n","1/6 [====>.........................] - ETA: 0s - loss: 12.6389 - accuracy: 0.7300\n","Epoch 54: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 19ms/step - loss: 9.0125 - accuracy: 0.5588 - val_loss: 5.3350 - val_accuracy: 0.6897\n","Epoch 55/100\n","1/6 [====>.........................] - ETA: 0s - loss: 5.4048 - accuracy: 0.6600\n","Epoch 55: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 18ms/step - loss: 6.9762 - accuracy: 0.6821 - val_loss: 8.9371 - val_accuracy: 0.3103\n","Epoch 56/100\n","1/6 [====>.........................] - ETA: 0s - loss: 8.4750 - accuracy: 0.2300\n","Epoch 56: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 15ms/step - loss: 3.9978 - accuracy: 0.4894 - val_loss: 7.0294 - val_accuracy: 0.6897\n","Epoch 57/100\n","1/6 [====>.........................] - ETA: 0s - loss: 5.8202 - accuracy: 0.7300\n","Epoch 57: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 8.1458 - accuracy: 0.6782 - val_loss: 8.3232 - val_accuracy: 0.3103\n","Epoch 58/100\n","1/6 [====>.........................] - ETA: 0s - loss: 7.2008 - accuracy: 0.2900\n","Epoch 58: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 16ms/step - loss: 3.2836 - accuracy: 0.5549 - val_loss: 0.9231 - val_accuracy: 0.6897\n","Epoch 59/100\n","1/6 [====>.........................] - ETA: 0s - loss: 0.8877 - accuracy: 0.7200\n","Epoch 59: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 2.2273 - accuracy: 0.6089 - val_loss: 4.1709 - val_accuracy: 0.2931\n","Epoch 60/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.4991 - accuracy: 0.3300\n","Epoch 60: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 23ms/step - loss: 4.1084 - accuracy: 0.6281 - val_loss: 6.8782 - val_accuracy: 0.2931\n","Epoch 61/100\n","1/6 [====>.........................] - ETA: 0s - loss: 5.9234 - accuracy: 0.2700\n","Epoch 61: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 18ms/step - loss: 2.8274 - accuracy: 0.5318 - val_loss: 4.6699 - val_accuracy: 0.6897\n","Epoch 62/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.1844 - accuracy: 0.7300\n","Epoch 62: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 5.0179 - accuracy: 0.6146 - val_loss: 5.9018 - val_accuracy: 0.6897\n","Epoch 63/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.2602 - accuracy: 0.7100\n","Epoch 63: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 7.6819 - accuracy: 0.6744 - val_loss: 5.6134 - val_accuracy: 0.2931\n","Epoch 64/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.9184 - accuracy: 0.3500\n","Epoch 64: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 15ms/step - loss: 6.7496 - accuracy: 0.6378 - val_loss: 5.2991 - val_accuracy: 0.2931\n","Epoch 65/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.6861 - accuracy: 0.2400\n","Epoch 65: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 16ms/step - loss: 4.4580 - accuracy: 0.5318 - val_loss: 8.1175 - val_accuracy: 0.3103\n","Epoch 66/100\n","6/6 [==============================] - ETA: 0s - loss: 4.8217 - accuracy: 0.5491\n","Epoch 66: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 23ms/step - loss: 4.8217 - accuracy: 0.5491 - val_loss: 8.1893 - val_accuracy: 0.3103\n","Epoch 67/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.3999 - accuracy: 0.2900\n","Epoch 67: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 24ms/step - loss: 5.5815 - accuracy: 0.5395 - val_loss: 0.7814 - val_accuracy: 0.3276\n","Epoch 68/100\n","1/6 [====>.........................] - ETA: 0s - loss: 0.7845 - accuracy: 0.2800\n","Epoch 68: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 2.5620 - accuracy: 0.5453 - val_loss: 3.7698 - val_accuracy: 0.2931\n","Epoch 69/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.0183 - accuracy: 0.3100\n","Epoch 69: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 19ms/step - loss: 3.4217 - accuracy: 0.5241 - val_loss: 1.2621 - val_accuracy: 0.6897\n","Epoch 70/100\n","1/6 [====>.........................] - ETA: 0s - loss: 0.9622 - accuracy: 0.7300\n","Epoch 70: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 1.8379 - accuracy: 0.5491 - val_loss: 2.8514 - val_accuracy: 0.6897\n","Epoch 71/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.9007 - accuracy: 0.7100\n","Epoch 71: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 21ms/step - loss: 1.5808 - accuracy: 0.6435 - val_loss: 0.6448 - val_accuracy: 0.6897\n","Epoch 72/100\n","6/6 [==============================] - ETA: 0s - loss: 1.6708 - accuracy: 0.6146\n","Epoch 72: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 24ms/step - loss: 1.6708 - accuracy: 0.6146 - val_loss: 1.7325 - val_accuracy: 0.6897\n","Epoch 73/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.4774 - accuracy: 0.6800\n","Epoch 73: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 18ms/step - loss: 1.6158 - accuracy: 0.5472 - val_loss: 1.2351 - val_accuracy: 0.6897\n","Epoch 74/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.2850 - accuracy: 0.6900\n","Epoch 74: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2272 - accuracy: 0.6012 - val_loss: 0.7532 - val_accuracy: 0.6897\n","Epoch 75/100\n","1/6 [====>.........................] - ETA: 0s - loss: 0.6909 - accuracy: 0.7000\n","Epoch 75: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 18ms/step - loss: 1.9017 - accuracy: 0.6069 - val_loss: 0.6452 - val_accuracy: 0.6897\n","Epoch 76/100\n","1/6 [====>.........................] - ETA: 0s - loss: 0.6705 - accuracy: 0.7400\n","Epoch 76: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 1.6116 - accuracy: 0.6339 - val_loss: 3.7126 - val_accuracy: 0.2931\n","Epoch 77/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.2578 - accuracy: 0.3500\n","Epoch 77: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 6.0066 - accuracy: 0.6358 - val_loss: 11.0754 - val_accuracy: 0.3103\n","Epoch 78/100\n","1/6 [====>.........................] - ETA: 0s - loss: 9.8143 - accuracy: 0.2800\n","Epoch 78: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 29ms/step - loss: 9.6381 - accuracy: 0.4566 - val_loss: 15.8691 - val_accuracy: 0.6897\n","Epoch 79/100\n","1/6 [====>.........................] - ETA: 0s - loss: 15.0205 - accuracy: 0.6700\n","Epoch 79: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 19ms/step - loss: 10.5586 - accuracy: 0.5877 - val_loss: 8.4672 - val_accuracy: 0.3103\n","Epoch 80/100\n","1/6 [====>.........................] - ETA: 0s - loss: 8.0544 - accuracy: 0.2900\n","Epoch 80: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 24ms/step - loss: 13.7064 - accuracy: 0.6146 - val_loss: 12.1326 - val_accuracy: 0.6897\n","Epoch 81/100\n","1/6 [====>.........................] - ETA: 0s - loss: 9.9873 - accuracy: 0.7100\n","Epoch 81: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 19ms/step - loss: 7.0416 - accuracy: 0.4952 - val_loss: 12.2667 - val_accuracy: 0.6897\n","Epoch 82/100\n","1/6 [====>.........................] - ETA: 0s - loss: 9.8013 - accuracy: 0.6900\n","Epoch 82: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 16ms/step - loss: 9.8810 - accuracy: 0.6975 - val_loss: 9.2173 - val_accuracy: 0.3103\n","Epoch 83/100\n","1/6 [====>.........................] - ETA: 0s - loss: 7.4622 - accuracy: 0.3900\n","Epoch 83: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 15ms/step - loss: 7.3562 - accuracy: 0.5703 - val_loss: 11.2634 - val_accuracy: 0.6897\n","Epoch 84/100\n","1/6 [====>.........................] - ETA: 0s - loss: 8.7376 - accuracy: 0.7500\n","Epoch 84: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 4.4647 - accuracy: 0.5087 - val_loss: 9.2815 - val_accuracy: 0.6897\n","Epoch 85/100\n","1/6 [====>.........................] - ETA: 0s - loss: 7.9827 - accuracy: 0.6500\n","Epoch 85: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 17ms/step - loss: 6.9097 - accuracy: 0.5973 - val_loss: 2.7056 - val_accuracy: 0.6897\n","Epoch 86/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.6065 - accuracy: 0.7100\n","Epoch 86: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 19ms/step - loss: 3.6919 - accuracy: 0.6243 - val_loss: 2.6196 - val_accuracy: 0.6897\n","Epoch 87/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.1897 - accuracy: 0.6900\n","Epoch 87: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 25ms/step - loss: 1.8172 - accuracy: 0.6146 - val_loss: 3.0180 - val_accuracy: 0.3103\n","Epoch 88/100\n","1/6 [====>.........................] - ETA: 0s - loss: 3.2708 - accuracy: 0.2700\n","Epoch 88: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 19ms/step - loss: 3.6339 - accuracy: 0.5896 - val_loss: 7.8927 - val_accuracy: 0.3103\n","Epoch 89/100\n","1/6 [====>.........................] - ETA: 0s - loss: 6.9573 - accuracy: 0.3200\n","Epoch 89: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 20ms/step - loss: 4.5966 - accuracy: 0.6069 - val_loss: 2.5322 - val_accuracy: 0.2931\n","Epoch 90/100\n","1/6 [====>.........................] - ETA: 0s - loss: 2.2123 - accuracy: 0.2600\n","Epoch 90: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 20ms/step - loss: 3.0970 - accuracy: 0.5279 - val_loss: 1.4067 - val_accuracy: 0.6897\n","Epoch 91/100\n","1/6 [====>.........................] - ETA: 0s - loss: 1.5712 - accuracy: 0.6600\n","Epoch 91: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 24ms/step - loss: 1.8261 - accuracy: 0.5857 - val_loss: 1.6002 - val_accuracy: 0.2931\n","Epoch 92/100\n","6/6 [==============================] - ETA: 0s - loss: 6.0686 - accuracy: 0.6031\n","Epoch 92: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 24ms/step - loss: 6.0686 - accuracy: 0.6031 - val_loss: 11.2737 - val_accuracy: 0.3103\n","Epoch 93/100\n","1/6 [====>.........................] - ETA: 0s - loss: 9.2240 - accuracy: 0.3700\n","Epoch 93: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 31ms/step - loss: 9.1977 - accuracy: 0.4817 - val_loss: 18.6491 - val_accuracy: 0.6897\n","Epoch 94/100\n","1/6 [====>.........................] - ETA: 0s - loss: 15.0379 - accuracy: 0.7000\n","Epoch 94: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 32ms/step - loss: 9.7799 - accuracy: 0.6243 - val_loss: 2.1794 - val_accuracy: 0.2931\n","Epoch 95/100\n","6/6 [==============================] - ETA: 0s - loss: 6.4093 - accuracy: 0.6262\n","Epoch 95: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 37ms/step - loss: 6.4093 - accuracy: 0.6262 - val_loss: 6.5701 - val_accuracy: 0.3103\n","Epoch 96/100\n","6/6 [==============================] - ETA: 0s - loss: 4.0661 - accuracy: 0.5318\n","Epoch 96: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 41ms/step - loss: 4.0661 - accuracy: 0.5318 - val_loss: 2.5623 - val_accuracy: 0.2931\n","Epoch 97/100\n","6/6 [==============================] - ETA: 0s - loss: 2.8228 - accuracy: 0.5511\n","Epoch 97: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 27ms/step - loss: 2.8228 - accuracy: 0.5511 - val_loss: 0.6468 - val_accuracy: 0.6897\n","Epoch 98/100\n","1/6 [====>.........................] - ETA: 0s - loss: 0.6548 - accuracy: 0.6800\n","Epoch 98: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 25ms/step - loss: 1.4926 - accuracy: 0.6204 - val_loss: 2.3812 - val_accuracy: 0.6897\n","Epoch 99/100\n","6/6 [==============================] - ETA: 0s - loss: 1.7780 - accuracy: 0.5337\n","Epoch 99: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 24ms/step - loss: 1.7780 - accuracy: 0.5337 - val_loss: 4.5171 - val_accuracy: 0.6897\n","Epoch 100/100\n","1/6 [====>.........................] - ETA: 0s - loss: 4.5459 - accuracy: 0.6700\n","Epoch 100: val_accuracy did not improve from 0.70690\n","6/6 [==============================] - 0s 25ms/step - loss: 3.1321 - accuracy: 0.5318 - val_loss: 9.0577 - val_accuracy: 0.6897\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5e1192d4c0>"]},"metadata":{},"execution_count":17}],"source":["model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs = 100, batch_size = 100, callbacks=model_checkpoint_callback)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"S14kdYUfnDJh","executionInfo":{"status":"ok","timestamp":1681643267756,"user_tz":-330,"elapsed":10,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["model.load_weights(filepath=\"checkpoint.hdf5\")"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"p9DytXC0nDJi","executionInfo":{"status":"ok","timestamp":1681643267757,"user_tz":-330,"elapsed":10,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"IxghiPIInDJi","executionInfo":{"status":"ok","timestamp":1681643267757,"user_tz":-330,"elapsed":9,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["model_store = open(\"model.pkl\", \"wb\")\n","pickle.dump(model , model_store)\n","model_store.close()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMokZDPsnDJi","executionInfo":{"status":"ok","timestamp":1681643269805,"user_tz":-330,"elapsed":2056,"user":{"displayName":"Study Material","userId":"09920973746406953302"}},"outputId":"493f0089-b670-4135-d192-4d0edbea842c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"]}],"source":["# !pip install streamlit\n","# !pip install pyngrok\n","!ngrok authtoken 2OUvp7wQtqaCWchjOnajYgkug2c_83YMdMGU7WHikiS69um32"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srRP7yRrnDJj","executionInfo":{"status":"ok","timestamp":1681644102672,"user_tz":-330,"elapsed":15,"user":{"displayName":"Study Material","userId":"09920973746406953302"}},"outputId":"29c27549-bd7b-47e2-bd55-c3179b2b69ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["17/17 [==============================] - 0s 3ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [False],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True],\n","       [ True]])"]},"metadata":{},"execution_count":55}],"source":[]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQTo9K-XnDJj","executionInfo":{"status":"ok","timestamp":1681643678076,"user_tz":-330,"elapsed":838,"user":{"displayName":"Study Material","userId":"09920973746406953302"}},"outputId":"b09abbd3-5456-49d6-87c7-bbb09c687450"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting loanapp_v2.py\n"]}],"source":["%%writefile loanapp_v2.py\n","import pandas as pd\n","import streamlit as st\n","import pickle\n","import numpy as np\n","pickle_in = open('model.pkl', 'rb') \n","model = pickle.load(pickle_in)\n","def main():\n","    html_temp = \"\"\" \n","    <div style =\"background-color:yellow;padding:13px\"> \n","    <h1 style =\"color:black;text-align:center;\">Check your Loan Eligibility</h1> \n","    </div> \n","    \"\"\"\n","    st.markdown(html_temp, unsafe_allow_html = True) \n","    \n","    Gender = st.selectbox('Gender',(\"Male\",\"Female\"))\n","    Married = st.selectbox('Marital Status',(\"Unmarried\",\"Married\")) \n","    ApplicantIncome = st.number_input(\"Monthly Income in Rupees\") \n","    LoanAmount = st.number_input(\"Loan Amount in Rupees\")\n","    \n","    \n","    if st.button(\"Check\"): \n","      result = prediction(Gender, Married, ApplicantIncome, LoanAmount) \n","      st.success('Your loan is {}'.format(result))\n","    \n","def prediction(Gender, Married, ApplicantIncome, LoanAmount):\n","    \n","    if Gender == \"Male\":\n","        Gender = 1\n","    else:\n","        Gender = 0\n","\n","    if Married == \"Married\":\n","        Married = 1\n","    else:\n","        Married = 0\n","    pred = (model.predict([[Gender, Married, ApplicantIncome, LoanAmount]]) > 0.5)\n","    if pred[0][0] == False:\n","      return \"Not Approved\"\n","    else:\n","      return \"Approved\"\n","    \n","if __name__=='__main__': \n","    main()\n","        \n","        \n","        "]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Vl9A8c7vnDJk","executionInfo":{"status":"ok","timestamp":1681643678076,"user_tz":-330,"elapsed":7,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"outputs":[],"source":["!streamlit run loanapp_v2.py &>/dev/null&"]},{"cell_type":"code","source":["from pyngrok import ngrok"],"metadata":{"id":"fbC8oTV90GLN","executionInfo":{"status":"ok","timestamp":1681644381992,"user_tz":-330,"elapsed":4,"user":{"displayName":"Study Material","userId":"09920973746406953302"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qEJxTdXu0J_h"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}